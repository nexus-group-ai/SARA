{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with LLMs and RAG\n",
    "\n",
    "Note: First create a filtered dataset with `filter-dataset.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:12:28.784978Z",
     "start_time": "2025-03-21T11:12:28.772943Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import pickle\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.llm import get_azure_embeddings_client, get_llm_client, get_gemini_llm_client\n",
    "\n",
    "if not load_dotenv():\n",
    "    raise Exception('Error loading .env file. Make sure to place valid keys in the .env file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:14:35.644042Z",
     "start_time": "2025-03-21T11:14:35.632207Z"
    }
   },
   "outputs": [],
   "source": [
    "ARTICLES_CLEAN_DIR = os.path.join(\"..\", \"data\", \"articles_clean\")\n",
    "FILTERED_METADATA_PATH = os.path.join(\"..\", \"data\", \"filtered_metadata.csv\")\n",
    "DB_PATH = os.path.join(\"..\", \"data\", \"db\", \"sample.db\")\n",
    "\n",
    "if not os.path.exists(DB_PATH):\n",
    "    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:15:00.943850Z",
     "start_time": "2025-03-21T11:15:00.903439Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_metadata = pd.read_csv(FILTERED_METADATA_PATH)\n",
    "filtered_metadata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simple vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents_from_path(filenames: list[str]) -> [Document]:\n",
    "    documents = []\n",
    "    \n",
    "    for file_name in filenames:\n",
    "        file_path = os.path.join(ARTICLES_CLEAN_DIR, file_name)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            file = json.load(file)\n",
    "\n",
    "        text = file.get(\"text\", \"\")\n",
    "        documents.append(Document(page_content=text, metadata={\n",
    "            \"title\": file.get(\"title\", \"\"),\n",
    "            \"author\": file.get(\"author\", \"\"),\n",
    "            \"published_at\": file.get(\"published_at\", \"\"),\n",
    "            \"id\": file.get(\"id\", \"\"),\n",
    "        }))\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_documents_from_path(filtered_metadata[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, separators=[\"\\n\\n\", \"\\n\"])\n",
    "\n",
    "# Split documents and create vector database\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = get_azure_embeddings_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count build embedding token number\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "build_token_count = sum([len(tokenizer.encode(doc.page_content)) for doc in texts])\n",
    "print(f\"Token count: {build_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the database\n",
    "with open(DB_PATH, \"wb\") as f:\n",
    "    pickle.dump(db.serialize_to_bytes(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI: free tier Gemini LLM \n",
    "# rate_limiter = InMemoryRateLimiter(\n",
    "#     requests_per_second=0.5,  # <-- Gemini Free Tier\n",
    "#     check_every_n_seconds=0.1,\n",
    "# )\n",
    "\n",
    "# llm = get_gemini_llm_client(\n",
    "#     max_tokens=1024,\n",
    "#     temperature=0.2,\n",
    "#     rate_limiter=rate_limiter,\n",
    "# )\n",
    "\n",
    "# Openrouter LLM\n",
    "llm = get_llm_client(\n",
    "    # Configurable parameters\n",
    "    max_tokens=1024,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert assistant. Use only the following retrieved context to answer the question accurately and concisely. \n",
    "If nothing is mentioned in the context, say \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], \n",
    "    template=system_prompt\n",
    ")\n",
    "\n",
    "retrieval_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(query):\n",
    "    response = retrieval_chain.invoke({\"query\": query})\n",
    "    print(f\"Question: {query}\\nAnswer: {response['result']}\")\n",
    "    print(\"\\nSources: \\n\")\n",
    "    for source in response[\"source_documents\"]:\n",
    "        print(source.metadata)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_question(\"What are the current economic threats in Austria?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
